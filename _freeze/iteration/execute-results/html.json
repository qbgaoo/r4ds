{
  "hash": "92a6991b46892921b6637f7a1eb0d921",
  "result": {
    "engine": "knitr",
    "markdown": "# 迭代 {#sec-iteration}\n\n\n::: {.cell}\n\n:::\n\n\n## 引言\n\n在这一章中，你将学习到用于迭代的工具，即在不同对象上重复执行相同的操作。R\n语言中的迭代通常看起来与其他编程语言有很大的不同，因为R语言中的很多迭代是隐式的，我们可以免费得到它。\n\n例如，如果你想在R中将数值向量`x`翻倍，只需写`2 * x`即可。而\n在大多数其他语言中，你可能需要使用某种形式的for循环来明确地将`x`的每个元素翻倍。\n\n本书已经向你介绍了一些虽小但功能强大的工具，这些工具可以对多个“事物”执行相同的操作：\n\n-   `facet_wrap()` 和 `facet_grid()` 为每个子集绘制一个图形；\n-   `group_by()` 加上 `summarize()` 为每个子集计算摘要统计统计量；\n-   `unnest_wider()` 和 `unnest_longer()` 为列表列中的每个元素创建新的行和列。\n\n现在是时候学习一些更通用的工具了，这些工具通常被称为函数式编程 (**functional programming**) 工具，因为它们建立在将其他函数作为输入的函数之上。学\n习函数式编程可能会变得抽象化，但在本章中，我们将通过关注三个常见任务来使内容具体化：修改多个列、读取多个文件以及保存多个对象。\n\n### 必要条件\n\n在本章中，我们将重点关注由dplyr和purrr提供的工具，它们都是tidyverse的核心成员。你\n之前已经见过dplyr，但`purrr`是新的。我\n们本章只会使用purrr的几个函数，但随着你编程技能的提高，它是一个非常值得探索的包。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n## 修改多列 {#sec-across}\n\n想象一下你有一个简单的tibble，你想要计算每一列的观察值数量以及每一列的中位数。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n```\n:::\n\n\n你可以使用复制-粘贴:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n#> # A tibble: 1 × 5\n#>       n      a      b       c     d\n#>   <int>  <dbl>  <dbl>   <dbl> <dbl>\n#> 1    10 -0.246 -0.287 -0.0567 0.144\n```\n:::\n\n\n这打破了我们的经验法则，即永远不要复制粘贴超过两次，你可以想象，如果你有数十甚至数百列，这将变得非常繁琐。相\n反，你可以使用`across()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> summarize(\n  n = n(),\n  across(a:d, median),\n)\n#> # A tibble: 1 × 5\n#>       n      a      b       c     d\n#>   <int>  <dbl>  <dbl>   <dbl> <dbl>\n#> 1    10 -0.246 -0.287 -0.0567 0.144\n```\n:::\n\n\n`across()`函数有三个特别重要的参数，我们将在以下部分中详细讨论它们。每\n次使用`across()`时，你都会使用前两个参数：第一个参数`.cols`指定你想要遍历的列，第二个参数`.fns`指定要对每一列执行的操作。当\n你需要对输出列的名称进行额外控制时，可以使用`.names`参数，这在与`mutate()`函数一起使用`across()`时尤为重要。此\n外，我们还将讨论两个重要的变体`if_any()`和`if_all()`，它们与`filter()`函数一起工作。\n\n### 使用`.cols`选择列\n\n`across()`函数的第一个参数`.cols`用于选择要进行转换的列。这\n与`select()`函数的指定方式相同，因此你可以使用像`starts_with()`和`ends_with()`这样的函数，根据列名来选择列。\n\n有两种额外的选择技术对于`across()`特别有用：`everything()`和`where()`。`e`\n`verything()`很简单：它选择所有（非分组）列：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |> \n  group_by(grp) |> \n  summarize(across(everything(), median))\n#> # A tibble: 2 × 5\n#>     grp       a       b     c     d\n#>   <int>   <dbl>   <dbl> <dbl> <dbl>\n#> 1     1 -0.0935 -0.0163 0.363 0.364\n#> 2     2  0.312  -0.0576 0.208 0.565\n```\n:::\n\n\n注意，分组列（在此处为 `grp`）不会被包含在`across()`中，因为它们在`summarize()`中会被自动保留。\n\n`where()`允许你根据列的类型来选择列：\n\n-   `where(is.numeric)` 选择所有数值列。\n-   `where(is.character)` 选择所有字符串列。\n-   `where(is.Date)` 选择所有日期列。\n-   `where(is.POSIXct)` 选择所有日期时间列。\n-   `where(is.logical)` 选择所有逻辑列。\n\n就像其他选择器一样，你可以使用布尔代数将它们组合起来。例\n如 `!where(is.numeric)` 选择所有非数值列，而 `starts_with(\"a\") & where(is.logical)` 选择所有名称以 \"a\" 开头的逻辑列。\n\n### 调用单个函数\n\n`across()` 的第二个参数定义了将如何转换每一列。在\n如上所述的简单例子中，这将是一个现有的函数。这\n是 R 语言的一个非常特别的功能：我们将一个函数 (如 `median`、`mean`、`str_flatten` 等) 传递给另一个函数 (即`across`)。这\n是使 R 成为一种函数式编程语言的特性之一。\n\n需要注意的是，我们将这个函数传递给`across()`，因此是`across()`来调用它，我们自己不直接调用它。这\n意味着函数名后面不应该有括号 `()`。如\n果你忘记了这一点，将会得到一个错误：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  group_by(grp) |> \n  summarize(across(everything(), median()))\n#> Error in `summarize()`:\n#> ℹ In argument: `across(everything(), median())`.\n#> Caused by error in `median.default()`:\n#> ! argument \"x\" is missing, with no default\n```\n:::\n\n\n出现此错误是因为你在没有输入的情况下调用函数，例如:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian()\n#> Error in median.default(): argument \"x\" is missing, with no default\n```\n:::\n\n\n### 调用多个函数\n\n在更复杂的情况下，你可能想要提供额外的参数或执行多个转换。让\n我们用一个简单的例子来说明这个问题：如果我们的数据中有一些缺失值，会发生什么？`m`\n`edian()`函数会传播这些缺失值，导致我们得到一个次优的输出：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrnorm_na <- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss <- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |> \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n#> # A tibble: 1 × 5\n#>       a     b     c     d     n\n#>   <dbl> <dbl> <dbl> <dbl> <int>\n#> 1    NA    NA    NA  1.15     5\n```\n:::\n\n\n如果我们能够将`na.rm = TRUE`传递给`median()`来移除这些缺失值，那将是非常好的。要\n做到这一点，我们需要创建一个新函数，该函数以期望的参数调用`median()`，而不是直接调用`median()`。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss |> \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n#> # A tibble: 1 × 5\n#>       a     b      c     d     n\n#>   <dbl> <dbl>  <dbl> <dbl> <int>\n#> 1 0.139 -1.11 -0.387  1.15     5\n```\n:::\n\n\n这样写有些冗长，所以 R 提供了一个方便的快捷方式：对于这种一次性或匿名函数[^iteration-1]，你可以使用`\\`[^iteration-2]来代替`function`。\n\n[^iteration-1]: 匿名，是因为我们从未用`<-`明确给它一个名称。程\n    序员用来称呼这种函数的另一个术语是“lambda 函数”。\n\n[^iteration-2]: 在旧版本的代码中，你可能会看到像`~ .x + 1`这样的语法。这\n    是编写匿名函数的另一种方式，但它只能在 tidyverse 函数内部使用，并且总是使用变量名`.x`。现\n    在我们推荐使用基础语法，即`\\(x) x + 1`。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss |> \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n```\n:::\n\n\n在任何情况下，`across()`实际上都会展开为以下代码：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss |> \n  summarize(\n    a = median(a, na.rm = TRUE),\n    b = median(b, na.rm = TRUE),\n    c = median(c, na.rm = TRUE),\n    d = median(d, na.rm = TRUE),\n    n = n()\n  )\n```\n:::\n\n\n当我们从`median()`中移除缺失值时，知道移除了多少值会很有用。我\n们可以通过向`across()`提供两个函数来找出这一点：一个用于计算中位数，另一个用于计算缺失值的数量。你\n可以通过向`.fns`提供一个命名列表来提供多个函数。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss |> \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n#> # A tibble: 1 × 9\n#>   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#>      <dbl>    <int>    <dbl>    <int>    <dbl>    <int>    <dbl>    <int>\n#> 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#> # ℹ 1 more variable: n <int>\n```\n:::\n\n\n如果你仔细观察，你可能会直觉地认为列名是使用类似`{.col}_{.fn}`的 glue 规范(@sec-glue) 来命名的，其中`.col`是原始列的名称，`.fn`是函数的名称。这\n并不是巧合！正\n如你将在下一节中学到的，你可以使用`.names`参数来提供你自己的 glue 规范。\n\n### 列名\n\n`across()`函数的结果是根据`.names`参数中提供的规范来命名的。如\n果我们想要函数的名字首先出现[^iteration-3]，可以自己指定。\n\n[^iteration-3]: 当前不能更改列的顺序，但可以在事后使用`relocate()`或类似的方法重新排序。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss |> \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n#> # A tibble: 1 × 9\n#>   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#>      <dbl>    <int>    <dbl>    <int>    <dbl>    <int>    <dbl>    <int>\n#> 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#> # ℹ 1 more variable: n <int>\n```\n:::\n\n\n`.names`参数在你使用`across()`与`mutate()`一起时特别重要。默\n认情况下，`across()`的输出会使用与输入相同的名称。这\n意味着在`mutate()`内部的`across(` 会替换现有的列。例如，在这里我们使用`coalesce()`来将 `NA` 值替换为 `0`：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss |> \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n#> # A tibble: 5 × 4\n#>        a      b      c     d\n#>    <dbl>  <dbl>  <dbl> <dbl>\n#> 1  0.434 -1.25   0     1.60 \n#> 2  0     -1.43  -0.297 0.776\n#> 3 -0.156 -0.980  0     1.15 \n#> 4 -2.61  -0.683 -0.785 2.13 \n#> 5  1.11   0     -0.387 0.704\n```\n:::\n\n\n如果想要创建新的列，你可以使用`.names`参数来为输出指定新的名称：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_miss |> \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0), .names = \"{.col}_na_zero\")\n  )\n#> # A tibble: 5 × 8\n#>        a      b      c     d a_na_zero b_na_zero c_na_zero d_na_zero\n#>    <dbl>  <dbl>  <dbl> <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n#> 1  0.434 -1.25  NA     1.60      0.434    -1.25      0         1.60 \n#> 2 NA     -1.43  -0.297 0.776     0        -1.43     -0.297     0.776\n#> 3 -0.156 -0.980 NA     1.15     -0.156    -0.980     0         1.15 \n#> 4 -2.61  -0.683 -0.785 2.13     -2.61     -0.683    -0.785     2.13 \n#> 5  1.11  NA     -0.387 0.704     1.11      0        -0.387     0.704\n```\n:::\n\n\n### 筛选\n\n`across()`非常适合与`summarize()`和`mutate()`一起使用，但是与`filter()`一起使用时则显得不太方便，因为你通常使用`|`或`&`来组合多个条件。显\n然，`across()`可以帮助创建多个逻辑列，但接下来怎么做呢？因\n此，dplyr 提供了`across()`的两个变体，分别叫做`if_any()`和`if_all()`：\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# same as df_miss |> filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\ndf_miss |> filter(if_any(a:d, is.na))\n#> # A tibble: 4 × 4\n#>        a      b      c     d\n#>    <dbl>  <dbl>  <dbl> <dbl>\n#> 1  0.434 -1.25  NA     1.60 \n#> 2 NA     -1.43  -0.297 0.776\n#> 3 -0.156 -0.980 NA     1.15 \n#> 4  1.11  NA     -0.387 0.704\n\n# same as df_miss |> filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\ndf_miss |> filter(if_all(a:d, is.na))\n#> # A tibble: 0 × 4\n#> # ℹ 4 variables: a <dbl>, b <dbl>, c <dbl>, d <dbl>\n```\n:::\n\n\n### 函数中的 `across()`\n\n`across()`在编程时特别有用，因为它允许你对多个列进行操作。例\n如，[Jacob Scott](https://twitter.com/_wurli/status/1571836746899283969) 使用了一个辅助函数，这个函数封装了一组`lubridate`函数，用于将所有日期列扩展为年、月和日列：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexpand_dates <- function(df) {\n  df |> \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date <- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |> \n  expand_dates()\n#> # A tibble: 2 × 5\n#>   name  date       date_year date_month date_day\n#>   <chr> <date>         <dbl>      <dbl>    <int>\n#> 1 Amy   2009-08-03      2009          8        3\n#> 2 Bob   2010-01-16      2010          1       16\n```\n:::\n\n\n`across()`还使得在一个参数中提供多个列变得容易，因为第一个参数使用了整齐选择，你只需要记住要拥抱这个参数，正如我们在 @sec-embracing 所讨论的。例\n如，这个函数默认会计算数字列的均数。但\n是，通过提供第二个参数，你可以选择仅汇总选定的列：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarize_means <- function(df, summary_vars = where(is.numeric)) {\n  df |> \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\ndiamonds |> \n  group_by(cut) |> \n  summarize_means()\n#> # A tibble: 5 × 9\n#>   cut       carat depth table price     x     y     z     n\n#>   <ord>     <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int>\n#> 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#> 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#> 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#> 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#> 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |> \n  group_by(cut) |> \n  summarize_means(c(carat, x:z))\n#> # A tibble: 5 × 6\n#>   cut       carat     x     y     z     n\n#>   <ord>     <dbl> <dbl> <dbl> <dbl> <int>\n#> 1 Fair      1.05   6.25  6.18  3.98  1610\n#> 2 Good      0.849  5.84  5.85  3.64  4906\n#> 3 Very Good 0.806  5.74  5.77  3.56 12082\n#> 4 Premium   0.892  5.97  5.94  3.65 13791\n#> 5 Ideal     0.703  5.51  5.52  3.40 21551\n```\n:::\n\n\n### 与 `pivot_longer()` 比较\n\n在继续之前，值得一提的是`across()`和`pivot_longer()`之间的一个有趣联系 (@sec-pivoting)。在\n许多情况下要执行相同的计算，你首先要重塑数据，然后按组(而不是按列)执行操作。以\n下面这个多函数总汇总例:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  summarize(across(a:d, list(median = median, mean = mean)))\n#> # A tibble: 1 × 8\n#>   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#>      <dbl>  <dbl>    <dbl>  <dbl>    <dbl>  <dbl>    <dbl>  <dbl>\n#> 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n```\n:::\n\n\n我们可以通过将数据重塑为长格式，然后进行汇总计算得到相同的值：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong <- df |> \n  pivot_longer(a:d) |> \n  group_by(name) |> \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n#> # A tibble: 4 × 3\n#>   name   median   mean\n#>   <chr>   <dbl>  <dbl>\n#> 1 a      0.0380 0.205 \n#> 2 b     -0.0163 0.0910\n#> 3 c      0.260  0.0716\n#> 4 d      0.540  0.508\n```\n:::\n\n\n如果你想要与`across()`相同的结构，你可以再次重塑:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong |> \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n#> # A tibble: 1 × 8\n#>   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#>      <dbl>  <dbl>    <dbl>  <dbl>    <dbl>  <dbl>    <dbl>  <dbl>\n#> 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n```\n:::\n\n\n了解这种技术是很有用的，因为有时你会遇到目前无法使用`across()`解决的问题：当有一组列，你想要同时对这些列进行计算时。例\n如，假设我们的数据框同时包含值和权重，并且我们想要计算加权平均数：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_paired <- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n```\n:::\n\n\n目前无法使用`across()`[^iteration-4]完成这个操作，但使用`pivot_longer()`相对来说比较直接：\n\n[^iteration-4]: 也许有一天会有，但目前我们还不知道如何实现。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_long <- df_paired |> \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n#> # A tibble: 40 × 3\n#>   group    val   wts\n#>   <chr>  <dbl> <dbl>\n#> 1 a      0.715 0.518\n#> 2 b     -0.709 0.691\n#> 3 c      0.718 0.216\n#> 4 d     -0.217 0.733\n#> 5 a     -1.09  0.979\n#> 6 b     -0.209 0.675\n#> # ℹ 34 more rows\n\ndf_long |> \n  group_by(group) |> \n  summarize(mean = weighted.mean(val, wts))\n#> # A tibble: 4 × 2\n#>   group    mean\n#>   <chr>   <dbl>\n#> 1 a      0.126 \n#> 2 b     -0.0704\n#> 3 c     -0.360 \n#> 4 d     -0.248\n```\n:::\n\n\n如果需要，您可以将`pivot_wider()`返回到原始形式。\n\n### 练习\n\n1.  通过以下方式练习你的 `across()`技能：\n\n    1.  计算`palmerpenguins::penguins`数据集中每一列的唯一值个数。\n\n    2.  计算`mtcars`中每一列的均数。\n\n    3.  按`cut`、`clarity`和`color`对`diamonds`进行分组，然后计算每个数值列的观测值个数以及均数。\n\n2.  如果在`across()`中使用函数列表但没有为它们命名，会发生什么？输\n    出是如何命名的？\n\n3.  调整`expand_dates()`函数，以便在日期列被扩展后自动删除它们。你\n    需要拥抱任何参数吗？\n\n4.  解释这个函数中管道的每一步都做了什么。利\n    用了`where()`的什么特殊功能？\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    show_missing <- function(df, group_vars, summary_vars = everything()) {\n      df |> \n        group_by(pick({{ group_vars }})) |> \n        summarize(\n          across({{ summary_vars }}, \\(x) sum(is.na(x))),\n          .groups = \"drop\"\n        ) |>\n        select(where(\\(x) any(x > 0)))\n    }\n    nycflights13::flights |> show_missing(c(year, month, day))\n    ```\n    :::\n\n\n## 读取多个文件\n\n在上一节中，学习了如何使用`dplyr::across()`对多列重复进行转换。在\n本节中，你将学习如何使用`purrr::map()`对目录中的每个文件执行某项操作。让\n我们从一个简单的动机开始：假设你有一个包含大量 Excel 表格的目录[^iteration-5]，你想要读取它们。\n可以使用复制和粘贴的方式来做这件事：\n\n[^iteration-5]: 如果你有一个包含相同格式 CSV 文件的目录，你可以使用 @sec-import-spreadsheets 中的方法。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata2019 <- readxl::read_excel(\"data/y2019.xlsx\")\ndata2020 <- readxl::read_excel(\"data/y2020.xlsx\")\ndata2021 <- readxl::read_excel(\"data/y2021.xlsx\")\ndata2022 <- readxl::read_excel(\"data/y2022.xlsx\")\n```\n:::\n\n\n然后可以使用`dplyr::bind_rows()`将它们合并在一起：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- bind_rows(data2019, data2020, data2021, data2022)\n```\n:::\n\n\n你可以想象，如果文件数量不是四个，而是成百上千个，那么这个过程很快就会变得繁琐。以\n下部分将向你展示如何自动化此类任务。主\n要有三个基本步骤：使用`list.files()`列出目录中的所有文件，然后使用`purrr::map()`将它们读入到一个列表中，接着使用`purrr::list_rbind()`将它们合并成一个单一的数据框。之\n后，我们将讨论如何处理日益增加的异质性情况，即你不能对每个文件都执行完全相同的操作。\n\n### 列出目录中的文件\n\n顾名思义，`list.files()`会列出目录中的文件。你\n总是会使用以下三个参数：\n\n-   第一个参数`path`是要查找的目录。\n-   `pattern`是一个用于过滤文件名的正则表达式。最常见的模式是类似`\\.xlsx$`或`\\.csv$`这样的表达式，用于查找具有指定扩展名的所有文件。\n-   `full.names`决定是否在输出中包含目录名。你通常希望这个参数为`TRUE`。\n\n为了让我们的动机示例具体化，这本书包含一个文件夹，其中包含来自`gapminder`包的 12 个 Excel 表格。每\n个文件包含 142 个国家某一年的数据。我\n们可以通过适当的`list.files()`调用列出所有这些文件：\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths <- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\npaths\n#>  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#>  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#>  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#>  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#>  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#> [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n```\n:::\n\n\n### 列表\n\n现在我们有了 12 个路径，我们可以调用`read_excel()` 12 次来得到 12 个数据框：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder_1952 <- readxl::read_excel(\"data/gapminder/1952.xlsx\")\ngapminder_1957 <- readxl::read_excel(\"data/gapminder/1957.xlsx\")\ngapminder_1962 <- readxl::read_excel(\"data/gapminder/1962.xlsx\")\n ...,\ngapminder_2007 <- readxl::read_excel(\"data/gapminder/2007.xlsx\")\n```\n:::\n\n\n但是将每个工作表放入自己的变量中将使得在后续的步骤中处理它们变得困难。相\n反，如果将它们放入一个单独的对象中，处理起来将更加方便。列\n表是完成这项工作的完美工具：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- list(\n  readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n```\n:::\n\n\n\n\n既然已经将这些数据框放入了一个列表中，如何从中取出一个呢？可\n以使用`files[[i]]`来提取第`i`个元素：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles[[3]]\n#> # A tibble: 142 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         32.0 10267083      853.\n#> 2 Albania     Europe       64.8  1728137     2313.\n#> 3 Algeria     Africa       48.3 11000948     2551.\n#> 4 Angola      Africa       34    4826015     4269.\n#> 5 Argentina   Americas     65.1 21283783     7133.\n#> 6 Australia   Oceania      70.9 10794968    12217.\n#> # ℹ 136 more rows\n```\n:::\n\n\n我们将在 @sec-subset-one 中更详细地讨论 `[[` 。\n\n### `purrr::map()` 和 `list_rbind()`\n\n手动将这些数据框收集到一个列表中的代码基本上和逐个读取文件的代码一样繁琐。幸\n运的是，我们可以使用`purrr::map()`来更好地利用我们的路径向量。`m`\n`ap()`函数与`across()`类似，但`map()`是对向量中的每个元素进行操作，而不是对数据框中的每列进行操作。`m`\n`ap(x, f)`是以下操作的简写：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  f(x[[1]]),\n  f(x[[2]]),\n  ...,\n  f(x[[n]])\n)\n```\n:::\n\n\n所以可以使用`map()`来获取一个包含12个数据框的列表:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- map(paths, readxl::read_excel)\nlength(files)\n#> [1] 12\n\nfiles[[1]]\n#> # A tibble: 142 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.\n#> 2 Albania     Europe       55.2  1282697     1601.\n#> 3 Algeria     Africa       43.1  9279525     2449.\n#> 4 Angola      Africa       30.0  4232095     3521.\n#> 5 Argentina   Americas     62.5 17876956     5911.\n#> 6 Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 136 more rows\n```\n:::\n\n\n(这是另一种数据结构，使用`str()`显示时可能不会特别紧凑，因此你可能希望将其加载到 RStudio 中并使用`View()`来检查它。)\n\n现在我们可以使用`purrr::list_rbind()`将这个数据框列表合并成一个单一的数据框：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist_rbind(files)\n#> # A tibble: 1,704 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.\n#> 2 Albania     Europe       55.2  1282697     1601.\n#> 3 Algeria     Africa       43.1  9279525     2449.\n#> 4 Angola      Africa       30.0  4232095     3521.\n#> 5 Argentina   Americas     62.5 17876956     5911.\n#> 6 Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 1,698 more rows\n```\n:::\n\n\n我们也可以在管道中同时进行这两步:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> \n  map(readxl::read_excel) |> \n  list_rbind()\n```\n:::\n\n\n如果想向`read_excel()`传递额外的参数怎么办？我\n们可以使用与`across()`相同的方法。例\n如，使用`n_max = 1`来查看数据的前几行通常很有用：\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> \n  map(\\(path) readxl::read_excel(path, n_max = 1)) |> \n  list_rbind()\n#> # A tibble: 12 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.\n#> 2 Afghanistan Asia         30.3  9240934      821.\n#> 3 Afghanistan Asia         32.0 10267083      853.\n#> 4 Afghanistan Asia         34.0 11537966      836.\n#> 5 Afghanistan Asia         36.1 13079460      740.\n#> 6 Afghanistan Asia         38.4 14880372      786.\n#> # ℹ 6 more rows\n```\n:::\n\n\n这个很明显缺少了一些东西：没有`year`列，因为这个值记录在路径中，而不是单个文件中。接\n下来我们将解决这个问题。\n\n### 路径中的数据 {#sec-data-in-the-path}\n\n有时，文件名本身就是数据的一部分。在\n这个例子中，文件名包含了年份，而这个年份并没有在单个文件中被记录。要\n将这一列添加到最终的数据框中，我们需要做两件事：\n\n首先，我们给路径向量命名。最\n简单的方法是使用`set_names()`，该函数可以接受一个函数。在\n这里，我们使用`basename()`函数从完整路径中提取仅包含文件名的部分：\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> set_names(basename) \n#>                  1952.xlsx                  1957.xlsx \n#> \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n#>                  1962.xlsx                  1967.xlsx \n#> \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n#>                  1972.xlsx                  1977.xlsx \n#> \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n#>                  1982.xlsx                  1987.xlsx \n#> \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n#>                  1992.xlsx                  1997.xlsx \n#> \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n#>                  2002.xlsx                  2007.xlsx \n#> \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n```\n:::\n\n\n这些名称会自动被所有`map`函数保留，因此数据框列表将具有相同的名称：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- paths |> \n  set_names(basename) |> \n  map(readxl::read_excel)\n```\n:::\n\n\n这使得对`map()`的调用简写为:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- list(\n  \"1952.xlsx\" = readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  \"1957.xlsx\" = readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  \"1962.xlsx\" = readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  \"2007.xlsx\" = readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n```\n:::\n\n\n你也可以使用`[[`按名称提取元素:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles[[\"1962.xlsx\"]]\n#> # A tibble: 142 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         32.0 10267083      853.\n#> 2 Albania     Europe       64.8  1728137     2313.\n#> 3 Algeria     Africa       48.3 11000948     2551.\n#> 4 Angola      Africa       34    4826015     4269.\n#> 5 Argentina   Americas     65.1 21283783     7133.\n#> 6 Australia   Oceania      70.9 10794968    12217.\n#> # ℹ 136 more rows\n```\n:::\n\n\n然后，我们使用`list_rbind()`的`names_to`参数来告诉它将名称保存到一个名为`year`的新列中，并使用`readr::parse_number()`从字符串中提取数字。\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> \n  set_names(basename) |> \n  map(readxl::read_excel) |> \n  list_rbind(names_to = \"year\") |> \n  mutate(year = parse_number(year))\n#> # A tibble: 1,704 × 6\n#>    year country     continent lifeExp      pop gdpPercap\n#>   <dbl> <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1  1952 Afghanistan Asia         28.8  8425333      779.\n#> 2  1952 Albania     Europe       55.2  1282697     1601.\n#> 3  1952 Algeria     Africa       43.1  9279525     2449.\n#> 4  1952 Angola      Africa       30.0  4232095     3521.\n#> 5  1952 Argentina   Americas     62.5 17876956     5911.\n#> 6  1952 Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 1,698 more rows\n```\n:::\n\n\n在更复杂的情况下，可能有其他变量存储在目录名中，或者文件名可能包含多个数据部分。在\n这种情况下，使用`set_names()`（不带任何参数）来记录完整路径，然后使用`tidyr::separate_wider_delim()`和相关函数将它们转换为有用的列。\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> \n  set_names() |> \n  map(readxl::read_excel) |> \n  list_rbind(names_to = \"year\") |> \n  separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |> \n  separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n#> # A tibble: 1,704 × 8\n#>   dir       file  ext   country     continent lifeExp      pop gdpPercap\n#>   <chr>     <chr> <chr> <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n#> 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n#> 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n#> 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n#> 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n#> 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 1,698 more rows\n```\n:::\n\n\n### 保存工作\n\n既然你已经完成了所有这些辛苦的工作，得到了一个整齐的数据框，现在是保存工作成果的好时机了：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngapminder <- paths |> \n  set_names(basename) |> \n  map(readxl::read_excel) |> \n  list_rbind(names_to = \"year\") |> \n  mutate(year = parse_number(year))\n\nwrite_csv(gapminder, \"gapminder.csv\")\n```\n:::\n\n\n当你将来再次遇到这个问题时，你可以读取一个单独的 csv 文件。对\n于大型的和更丰富的数据集，使用 parquet 可能是比 `.csv` 更好的选择，正如在 @sec-parquet 中讨论的那样。\n\n\n\n\n\n如果你在一个项目中工作，我们建议你将执行这种数据准备工作的文件命名为类似 `0-cleanup.R` 的名字。文\n件名中的 `0` 表示这应该在其他任何事情之前运行。\n\n如果你的输入数据文件随着时间的推移而发生变化，你可能需要考虑学习一个工具，如 [targets](https://docs.ropensci.org/targets/)，来设置你的数据清理代码，以便在输入文件之一被修改时自动重新运行。\n\n### 多个简单迭代\n\n在这里，我们只是直接从磁盘加载了数据，并幸运地得到了一个整齐的数据集。在\n大多数情况下，你需要做一些额外的整理工作，有两个基本选项：你可以使用一个复杂的函数进行一轮迭代，或者使用简单的函数进行多轮迭代。根\n据我们的经验，大多数人首先选择一个复杂的迭代，但通常使用多个简单迭代会更好。\n\n例如，假设你想读取一堆文件，过滤掉缺失值，进行重塑，然后合并。解\n决这个问题的一个方法是编写一个函数，该函数接收一个文件并执行所有这些步骤，然后调用`map()`一次：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprocess_file <- function(path) {\n  df <- read_csv(path)\n  \n  df |> \n    filter(!is.na(id)) |> \n    mutate(id = tolower(id)) |> \n    pivot_longer(jan:dec, names_to = \"month\")\n}\n\npaths |> \n  map(process_file) |> \n  list_rbind()\n```\n:::\n\n\n或者，你可以对每个文件执行`process_file()`中的每个步骤：\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> \n  map(read_csv) |> \n  map(\\(df) df |> filter(!is.na(id))) |> \n  map(\\(df) df |> mutate(id = tolower(id))) |> \n  map(\\(df) df |> pivot_longer(jan:dec, names_to = \"month\")) |> \n  list_rbind()\n```\n:::\n\n\n我们推荐这种方法，因为它阻止你在移动到其余文件之前只关注第一个文件的正确性。通\n过在整理和清洗数据时考虑所有数据，你更有可能从整体上思考，并得出更高质量的结果。\n\n在这个特定的例子中，还有一个优化你可以做，那就是更早地将所有数据框绑定在一起。然\n后，你可以依赖常规的 dplyr 行为：\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> \n  map(read_csv) |> \n  list_rbind() |> \n  filter(!is.na(id)) |> \n  mutate(id = tolower(id)) |> \n  pivot_longer(jan:dec, names_to = \"month\")\n```\n:::\n\n\n### 异质数据\n\n不幸的是，有时无法直接从`map()`转到`list_rbind()`，因为数据框的异质性太强，导致`list_rbind()`失败或产生了一个不太有用的数据框。在\n这种情况下，从加载所有文件开始仍然是有用的：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- paths |> \n  map(readxl::read_excel) \n```\n:::\n\n\n然后，一个有用的策略是捕获数据框的结构，以便你可以使用数据科学技能来探索它。这\n样做的一种方法是使用下面这个`df_types`函数[^iteration-6]，它返回一个 tibble，其中每列对应一行：\n\n[^iteration-6]: 我们不会解释这个函数是如何工作的，但如果你查看所使用的函数的文档，应该能够自己弄清楚。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_types <- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder)\n#> # A tibble: 6 × 3\n#>   col_name  col_type  n_miss\n#>   <chr>     <chr>      <int>\n#> 1 year      double         0\n#> 2 country   character      0\n#> 3 continent character      0\n#> 4 lifeExp   double         0\n#> 5 pop       double         0\n#> 6 gdpPercap double         0\n```\n:::\n\n\n然后，你可以将这个函数应用于所有文件，并可能进行一些重塑操作，以便更容易地看到差异所在。例\n如，这可以很容易地验证我们一直在使用的 gapminder 电子表格是否都是同质的：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles |> \n  map(df_types) |> \n  list_rbind(names_to = \"file_name\") |> \n  select(-n_miss) |> \n  pivot_wider(names_from = col_name, values_from = col_type)\n#> # A tibble: 12 × 6\n#>   file_name country   continent lifeExp pop    gdpPercap\n#>   <chr>     <chr>     <chr>     <chr>   <chr>  <chr>    \n#> 1 1952.xlsx character character double  double double   \n#> 2 1957.xlsx character character double  double double   \n#> 3 1962.xlsx character character double  double double   \n#> 4 1967.xlsx character character double  double double   \n#> 5 1972.xlsx character character double  double double   \n#> 6 1977.xlsx character character double  double double   \n#> # ℹ 6 more rows\n```\n:::\n\n\n如果文件的格式是异构的，那么在成功合并它们之前，你可能需要进行更多的处理。不\n幸的是，接下来我们将让你自己去解决这个问题，但你可能想要阅读关于`map_if()`和`map_at()`的信息。`m`\n`ap_if()`允许你根据列表元素的值有选择地修改它们；`map_at()`允许你根据元素的名称有选择地修改它们。\n\n### 处理失败\n\n有时，你的数据结构可能极其复杂，以至于你甚至无法使用单个命令读取所有文件。然\n后你就会遇到`map()`的一个缺点：要么整体成功，要么整体失败。`m`\n`ap()`要么成功地读取目录中的所有文件，要么因为错误而失败，一个文件都读不到。这\n有点烦人：为什么一个失败就阻止你获得其他成功呢？\n\n幸运的是，`purrr`提供了一个辅助函数`possibly()`来解决这个问题。`p`\n`ossibly()`是一个函数操作符：它接受一个函数并返回一个行为经过修改过函数。具\n体来说，`possibly()`会将函数从错误改为返回你指定的值。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfiles <- paths |> \n  map(possibly(\\(path) readxl::read_excel(path), NULL))\n\ndata <- files |> list_rbind()\n```\n:::\n\n\n这个做法在这里特别有效，因为`list_rbind()`（像许多 tidyverse 函数一样）会自动忽略 `NULL` 值。\n\n现在你已经有了所有可以轻松读取的数据，是时候解决困难的部分了，即弄清楚为什么一些文件加载失败以及该如何处理它们。首\n先，获取那些失败的文件的路径：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfailed <- map_vec(files, is.null)\npaths[failed]\n#> character(0)\n```\n:::\n\n\n然后针对每个失败的文件再次调用导入函数，并找出哪里出了问题。\n\n## 保存多个输出\n\n上一个部分学习了`map()`函数，它对于将多个文件读取到单个对象中非常有用。在\n本部分，我们将探讨一个相反的问题：你如何能将一个或多个 R 对象保存到一个或多个文件中？我\n们将通过三个例子来探索这个挑战：\n\n-   将多个数据框保存到一个数据库中。\n-   将多个数据框保存到多个 `.csv` 文件中。\n-   将多个图保存到多个 `.png` 文件中。\n\n### 写入数据库 {#sec-save-database}\n\n有时在同时处理许多文件时，不可能将所有数据一次性加载到内存中，因此你无法使用`map(files, read_csv)`。处\n理这个问题的一种方法是将数据加载到数据库中，这样你就可以使用`dbplyr`仅访问你需要的部分。\n\n如果你很幸运，你所使用的数据库包会提供一个方便的函数，该函数接受一个路径向量并将它们全部加载到数据库中。这\n就是`duckdb`的`duckdb_read_csv()`函数的情况。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- DBI::dbConnect(duckdb::duckdb())\nduckdb::duckdb_read_csv(con, \"gapminder\", paths)\n```\n:::\n\n\n这种方法在这里会很有效，但我们没有 csv 文件，而是 Excel 电子表格，所以必须“手动”进行。当\n你有一堆csv，而你正在使用的数据库没有一个函数可以将它们全部加载进来时，学习手工操作也会对你有所帮助。\n\n我们需要首先创建一个表来填充数据。最\n简单的方法是通过创建一个模板，即一个包含我们想要的所有列但只包含样本数据的虚拟数据框。对\n于 gapminder 数据，我们可以通过读取单个文件并向其添加年份来创建该模板：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemplate <- readxl::read_excel(paths[[1]])\ntemplate$year <- 1952\ntemplate\n#> # A tibble: 142 × 6\n#>   country     continent lifeExp      pop gdpPercap  year\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl> <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.  1952\n#> 2 Albania     Europe       55.2  1282697     1601.  1952\n#> 3 Algeria     Africa       43.1  9279525     2449.  1952\n#> 4 Angola      Africa       30.0  4232095     3521.  1952\n#> 5 Argentina   Americas     62.5 17876956     5911.  1952\n#> 6 Australia   Oceania      69.1  8691212    10040.  1952\n#> # ℹ 136 more rows\n```\n:::\n\n\n现在我们可以连接到数据库，并使用`DBI::dbCreateTable()`将我们的模板转换为数据库表：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- DBI::dbConnect(duckdb::duckdb())\nDBI::dbCreateTable(con, \"gapminder\", template)\n```\n:::\n\n\n`dbCreateTable()`并不使用`template`中的数据，而只是使用变量名和类型。所\n以如果我们现在检查`gapminder`表，你会看到它是空的，但它具有我们需要的变量和预期的类型：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon |> tbl(\"gapminder\")\n#> # Source:   table<gapminder> [0 x 6]\n#> # Database: DuckDB v0.10.1 [root@Darwin 23.5.0:R 4.3.3/:memory:]\n#> # ℹ 6 variables: country <chr>, continent <chr>, lifeExp <dbl>, pop <dbl>,\n#> #   gdpPercap <dbl>, year <dbl>\n```\n:::\n\n\n接下来，我们需要一个函数，它接受一个单独的文件路径，将其读取到 R 中，并将结果添加到`gapminder`表中。我\n们可以通过将`read_excel()`与`DBI::dbAppendTable()`结合使用来实现这一点：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nappend_file <- function(path) {\n  df <- readxl::read_excel(path)\n  df$year <- parse_number(basename(path))\n  \n  DBI::dbAppendTable(con, \"gapminder\", df)\n}\n```\n:::\n\n\n现在我们需要对`paths`中的每个元素调用一次`append_file()`函数。这\n当然可以使用`map()`函数来实现：\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> map(append_file)\n```\n:::\n\n\n但是我们并不关心`append_file()`的输出，所以与`map()`相比，使用`walk()`稍微更合适。`w`\n`alk()`的功能与`map()`相同，但它会丢弃输出：\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaths |> walk(append_file)\n```\n:::\n\n\n现在我们可以看看表中是否有所有的数据:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon |> \n  tbl(\"gapminder\") |> \n  count(year)\n#> # Source:   SQL [?? x 2]\n#> # Database: DuckDB v0.10.1 [root@Darwin 23.5.0:R 4.3.3/:memory:]\n#>    year     n\n#>   <dbl> <dbl>\n#> 1  1977   142\n#> 2  1987   142\n#> 3  1967   142\n#> 4  2007   142\n#> 5  1952   142\n#> 6  1957   142\n#> # ℹ more rows\n```\n:::\n\n\n\n\n### 编写csv文件\n\n如果我们想要编写多个 csv 文件 (每个组一个) , 那么同样的基本原则也适用。让\n我们想象一下，我们想要获取`ggplot2::diamonds`数据，并为每种`clarity`保存一个 csv 文件。首\n先，我们需要创建这些单独的数据集。可\n以通过多种方式做到这一点，但有一种我们特别喜欢的方法：`group_nest()`。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nby_clarity <- diamonds |> \n  group_nest(clarity)\n\nby_clarity\n#> # A tibble: 8 × 2\n#>   clarity               data\n#>   <ord>   <list<tibble[,9]>>\n#> 1 I1               [741 × 9]\n#> 2 SI2            [9,194 × 9]\n#> 3 SI1           [13,065 × 9]\n#> 4 VS2           [12,258 × 9]\n#> 5 VS1            [8,171 × 9]\n#> 6 VVS2           [5,066 × 9]\n#> # ℹ 2 more rows\n```\n:::\n\n\n这会提供给我们一个新的tibble ，它有八行两列。`c`\n`larity`是我们的分组变量，而`data`是一个列表列，它包含每个`clarity`值对应的一个数据框：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nby_clarity$data[[1]]\n#> # A tibble: 741 × 9\n#>   carat cut       color depth table price     x     y     z\n#>   <dbl> <ord>     <ord> <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#> 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#> 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#> 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#> 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#> 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#> 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#> # ℹ 735 more rows\n```\n:::\n\n\n在这里，让我们使用`mutate()`和`str_glue()`创建一个列来给出输出文件的名称：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nby_clarity <- by_clarity |> \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n#> # A tibble: 8 × 3\n#>   clarity               data path             \n#>   <ord>   <list<tibble[,9]>> <glue>           \n#> 1 I1               [741 × 9] diamonds-I1.csv  \n#> 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#> 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#> 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#> 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#> 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#> # ℹ 2 more rows\n```\n:::\n\n\n所以，如果要手工保存这些数据框，我们可以这样写:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(by_clarity$data[[1]], by_clarity$path[[1]])\nwrite_csv(by_clarity$data[[2]], by_clarity$path[[2]])\nwrite_csv(by_clarity$data[[3]], by_clarity$path[[3]])\n...\nwrite_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])\n```\n:::\n\n\n这与我们之前使用`map()`的情况略有不同，因为有两个参数在变化，而不仅仅是一个。这\n意味着我们需要一个新函数`map2()`，它同时改变第一和第二个参数。因\n为我们同样不关心输出，所以想要使用`walk2()`而不是`map2()`。这\n给了我们：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwalk2(by_clarity$data, by_clarity$path, write_csv)\n```\n:::\n\n\n\n\n### 保存图形\n\n我们可以采用相同的基本方法来创建许多图形。让\n我们首先创建一个函数来绘制我们想要的图形:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncarat_histogram <- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n```\n\n::: {.cell-output-display}\n![](iteration_files/figure-html/unnamed-chunk-69-1.png){fig-alt='Histogram of carats of diamonds from the by_clarity dataset, ranging from\n0 to 5 carats. The distribution is unimodal and right skewed with a peak\naround 1 carat.' width=576}\n:::\n:::\n\n\n现在我们可以使用`map()`来创建一个包含多个图形[^iteration-7]及其最终文件路径的列表：\n\n[^iteration-7]: 你可以输出`by_clarity$plot`来得到一个粗略的动画——你会得到`plots`中每个元素的一个图形。注\n    意：这种情况并没有发生在我身上。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nby_clarity <- by_clarity |> \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n```\n:::\n\n\n然后使用`walk2()`和`ggsave()`来保存每个图形:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwalk2(\n  by_clarity$path,\n  by_clarity$plot,\n  \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n)\n```\n:::\n\n\n这是以下内容的简写:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)\nggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)\nggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)\n...\nggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)\n```\n:::\n\n\n\n```{=html}\n<!-- \n### Exercises\n\n1.  Imagine you have a table of student data containing (amongst other variables) `school_name` and `student_id`. Sketch out what code you'd write if you want to save all the information for each student in file called `{student_id}.csv` in the `{school}` directory.\n-->\n```\n\n## 小结\n\n在这一章中，你已经看到了如何使用显式迭代来解决在数据科学中经常遇到的三个问题：操作多个列、读取多个文件以及保存多个输出。但\n一般来说，迭代是一种超能力：如果你知道正确的迭代方法，可以很容易地从解决一个问题转变为解决所有问题。一\n旦你掌握了本章中的技术，我们强烈推荐你通过阅读《Advanced R》的 [Functionals chapter](https://adv-r.hadley.nz/functionals.html) 并查阅 [purrr website](https://purrr.tidyverse.org) 来进一步学习。\n\n如果你对其他语言中的迭代有所了解，可能会惊讶于我们没有讨论 for 循环。这\n是因为 R 的数据分析导向改变了我们迭代的方式：在大多数情况下，你可以依靠现有的习惯用法来对每个列或每个组执行某些操作。而\n当你不能这样做时，你通常可以使用像`map()`这样的函数式编程工具来对列表中的每个元素执行某些操作。然\n而，你将在原始代码中看到 for 循环，因此你将在下一章中学习它们，届时我们将讨论一些重要的基础 R 工具。\n",
    "supporting": [
      "iteration_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}