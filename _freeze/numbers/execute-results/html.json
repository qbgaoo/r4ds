{
  "hash": "4edc508b2b2dfdb3cc5820379abcd05f",
  "result": {
    "engine": "knitr",
    "markdown": "# 数值 {#sec-numbers}\n\n\n::: {.cell}\n\n:::\n\n\n## 引言\n\n数值向量是数据科学的基石，你在本书的前面部分已经多次使用过它们。现\n在是系统地审视你在R中可以对它们做什么的时候了，确保你能够很好地应对任何涉及数值向量的未来问题。\n\n我们将首先为你提供几个工具，以便在你有字符串时生成数字，然后更详细地介绍`count()`函数。然\n后，我们将深入探讨与`mutate()`搭配使用的各种数值转换，包括可以应用于其他类型向量的更一般的转换，但通常与数值向量一起使用。最\n后，我们将介绍与`summarize()`搭配使用的汇总函数，并向你展示它们也可以与`mutate()`一起使用。\n\n### 必要条件\n\n本章主要使用来自基础R的函数，这些函数无需加载任何包即可使用。但\n我们仍然需要tidyverse，因为我们将在tidyverse的函数（如`mutate()`和`filter()`）内部使用这些基础R函数。和\n上一章一样，我们将使用`nycflights13`数据集的真实示例，以及使用`c()`和`tribble()`创建的玩具示例。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(nycflights13)\n```\n:::\n\n\n## 数字化\n\n在大多数情况下，你会获得R的数字类型之一的整数或双精度数字。然\n而，在某些情况下你可能会遇到以字符串形式出现的数字，可能是因为从列标题中转换得到它们，或者是因为在数据导入过程中出现了某些问题。\n\n`readr`包提供了两个有用的函数来将字符串解析为数字：`parse_double()`和`parse_number()`。当\n你遇到以字符串形式写入的数字时，可以使用`parse_double()`。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(\"1.2\", \"5.6\", \"1e3\")\nparse_double(x)\n#> [1]    1.2    5.6 1000.0\n```\n:::\n\n\n当字符串中包含你想要忽略的非数字文本时，使用`parse_number()`。这\n对于货币数据和百分比特别有用：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(\"$1,234\", \"USD 3,513\", \"59%\")\nparse_number(x)\n#> [1] 1234 3513   59\n```\n:::\n\n\n## 计数 {#sec-counts}\n\n令人惊讶的是，仅仅通过计数和一些基本的算术运算你就能够完成不少数据科学工作，因此`dplyr`致力于通过`count()`函数使计数尽可能简单。这\n个函数非常适合在分析过程中进行快速探索和检查：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> count(dest)\n#> # A tibble: 105 × 2\n#>   dest      n\n#>   <chr> <int>\n#> 1 ABQ     254\n#> 2 ACK     265\n#> 3 ALB     439\n#> 4 ANC       8\n#> 5 ATL   17215\n#> 6 AUS    2439\n#> # ℹ 99 more rows\n```\n:::\n\n\n尽管在 @sec-workflow-style 给出了建议，但我们通常还是将`count()`放在单独的一行，因为它通常在控制台中用于快速检查计算是否按预期工作。\n\n如果你想看到最常见的值，添加 `sort = TRUE`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> count(dest, sort = TRUE)\n#> # A tibble: 105 × 2\n#>   dest      n\n#>   <chr> <int>\n#> 1 ORD   17283\n#> 2 ATL   17215\n#> 3 LAX   16174\n#> 4 BOS   15508\n#> 5 MCO   14082\n#> 6 CLT   14064\n#> # ℹ 99 more rows\n```\n:::\n\n\n请记住，如果希望查看所有值，可以使用`|> View()`或`|> print(n = Inf)`。\n\n你可以通过`group_by()`、`summarize()`和`n()`\"手动\"执行相同的计算。这\n是有用的，因为它允许你同时计算其他汇总统计量：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(dest) |> \n  summarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  )\n#> # A tibble: 105 × 3\n#>   dest      n delay\n#>   <chr> <int> <dbl>\n#> 1 ABQ     254  4.38\n#> 2 ACK     265  4.85\n#> 3 ALB     439 14.4 \n#> 4 ANC       8 -2.5 \n#> 5 ATL   17215 11.3 \n#> 6 AUS    2439  6.02\n#> # ℹ 99 more rows\n```\n:::\n\n\n`n()`是一个特殊的汇总函数，它不接受任何参数，而是访问关于“当前”组的信息。这\n意味着它只能在`dplyr`的函数内部使用：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn()\n#> Error in `n()`:\n#> ! Must only be used inside data-masking verbs like `mutate()`,\n#>   `filter()`, and `group_by()`.\n```\n:::\n\n\n`n()`和`count()`有几个变体，你可能会觉得它们有用：\n\n-   `n_distinct(x)`计算一个或多个变量的不同（唯一）值的数量。例\n    如，我们可以找出哪些目的地有最多的航空公司提供服务：\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    flights |> \n      group_by(dest) |> \n      summarize(carriers = n_distinct(carrier)) |> \n      arrange(desc(carriers))\n    #> # A tibble: 105 × 2\n    #>   dest  carriers\n    #>   <chr>    <int>\n    #> 1 ATL          7\n    #> 2 BOS          7\n    #> 3 CLT          7\n    #> 4 ORD          7\n    #> 5 TPA          7\n    #> 6 AUS          6\n    #> # ℹ 99 more rows\n    ```\n    :::\n\n\n-   加权计数是求和。例\n    如你可以“计数”每架飞机飞行的英里数：\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    flights |> \n      group_by(tailnum) |> \n      summarize(miles = sum(distance))\n    #> # A tibble: 4,044 × 2\n    #>   tailnum  miles\n    #>   <chr>    <dbl>\n    #> 1 D942DN    3418\n    #> 2 N0EGMQ  250866\n    #> 3 N10156  115966\n    #> 4 N102UW   25722\n    #> 5 N103US   24619\n    #> 6 N104UW   25157\n    #> # ℹ 4,038 more rows\n    ```\n    :::\n\n\n    加权计数是一个常见的问题，所以`count()`函数有一个`wt`参数来实现同样的功能：\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    flights |> count(tailnum, wt = distance)\n    ```\n    :::\n\n\n-   可以通过结合`sum()`和`is.na()`来计数缺失值。在\n    `flights`数据集中，这表示被取消的航班：\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    flights |> \n      group_by(dest) |> \n      summarize(n_cancelled = sum(is.na(dep_time))) \n    #> # A tibble: 105 × 2\n    #>   dest  n_cancelled\n    #>   <chr>       <int>\n    #> 1 ABQ             0\n    #> 2 ACK             0\n    #> 3 ALB            20\n    #> 4 ANC             0\n    #> 5 ATL           317\n    #> 6 AUS            21\n    #> # ℹ 99 more rows\n    ```\n    :::\n\n\n### 练习\n\n1.  如何使用`count()`来计算给定变量中缺失值的行数？\n2.  将以下对`count()`的调用扩展为使用`group_by()`、`summarize()`和`arrange()`:\n    1.  `flights |> count(dest, sort = TRUE)`\n\n    2.  `flights |> count(tailnum, wt = distance)`\n\n## 数值转换\n\n转换函数与`mutate()`配合得很好，因为它们的输出长度与输入相同。绝\n大多数转换函数已经内置在R的基本包中。列\n出所有函数是不切实际的，所以本节将展示一些最有用的。例\n如，虽然R提供了你可能梦寐以求的所有三角函数，但我们在这里没有列出它们，因为它们在数据科学中很少需要。\n\n### 算术和循环规则 {#sec-recycling}\n\n在 @sec-workflow-basics ，我们介绍了算术运算（`+`, `-`, `*`, `/`, `^`）的基础知识，并在此之后多次使用了它们。这\n些函数不需要过多的解释，因为它们执行的是你在小学就学过的运算。但\n是，我们需要简短地讨论一下循环规则（recycling rules），这些规则决定了当左侧和右侧的长度不同时会发生什么。这\n对于像`flights |> mutate(air_time = air_time / 60)`这样的操作很重要，因为在`/`的左侧有336,776个数字，而右侧只有一个。\n\nR通过循环或重复较短的向量来处理长度不匹配的情况。如\n果我们在数据框之外创建一些向量，就能更容易地看到这个操作过程：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1, 2, 10, 20)\nx / 5\n#> [1] 0.2 0.4 2.0 4.0\n# is shorthand for\nx / c(5, 5, 5, 5)\n#> [1] 0.2 0.4 2.0 4.0\n```\n:::\n\n\n通常，你只想循环单个数字（即长度为1的向量），但R会循环任何较短的向量。如\n果较长的向量不是较短的向量的倍数，R通常会（但不总是）给出警告：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx * c(1, 2)\n#> [1]  1  4 10 40\nx * c(1, 2, 3)\n#> Warning in x * c(1, 2, 3): longer object length is not a multiple of shorter\n#> object length\n#> [1]  1  4 30 20\n```\n:::\n\n\n这些循环规则也适用于逻辑比较（`==`, `<`, `<=`, `>`, `>=`, `!=`），如果你不小心使用了`==`而不是`%in%`，并且数据框的行数不巧地匹配了这些规则，可能会导致一个令人惊讶的结果。例\n如，考虑以下代码，它试图找出1月和2月的所有航班：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  filter(month == c(1, 2))\n#> # A tibble: 25,977 × 19\n#>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n#> 1  2013     1     1      517            515         2      830            819\n#> 2  2013     1     1      542            540         2      923            850\n#> 3  2013     1     1      554            600        -6      812            837\n#> 4  2013     1     1      555            600        -5      913            854\n#> 5  2013     1     1      557            600        -3      838            846\n#> 6  2013     1     1      558            600        -2      849            851\n#> # ℹ 25,971 more rows\n#> # ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>, …\n```\n:::\n\n\n代码运行无误，但它没有返回你想要的结果。由\n于循环规则，它找到了在奇数行出发的1月航班和在偶数行出发的2月航班。不\n幸的是，由于`flights`的行数是偶数所以没有给出警告。\n\n为了防止这种静默失败的情况，tidyverse的大多数函数使用了一种更严格的循环形式，即仅循环单个值。不\n幸的是，这在当前情况下或许多其他情况下并不起作用，因为关键的计算是由基础R函数`==`执行的，而不是`filter()`。\n\n### 最小值和最大值\n\n算术函数对变量对进行操作。两\n个紧密相关的函数是`pmin()`和`pmax()`，当给定两个或更多变量时，它们将返回每行中的最小或最大值：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- tribble(\n  ~x, ~y,\n  1,  3,\n  5,  2,\n  7, NA,\n)\n\ndf |> \n  mutate(\n    min = pmin(x, y, na.rm = TRUE),\n    max = pmax(x, y, na.rm = TRUE)\n  )\n#> # A tibble: 3 × 4\n#>       x     y   min   max\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     3     1     3\n#> 2     5     2     2     5\n#> 3     7    NA     7     7\n```\n:::\n\n\n请注意，这些函数与`min()`和`max()`这样的汇总函数是不同的，后者接受多个观测值并返回一个单一的值。当\n发现所有的最小值和所有的最大值都相同时，你可以判断你可能使用了错误的形式。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  mutate(\n    min = min(x, y, na.rm = TRUE),\n    max = max(x, y, na.rm = TRUE)\n  )\n#> # A tibble: 3 × 4\n#>       x     y   min   max\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1     1     3     1     7\n#> 2     5     2     1     7\n#> 3     7    NA     1     7\n```\n:::\n\n\n### 模运算\n\n模运算（modular arithmetic）是你在学习十进制之前所做的数学运算的技术名称，即除法产生一个整数商和一个余数。在\nR中，`%/%`执行整数除法，而`%%`计算余数。\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1:10 %/% 3\n#>  [1] 0 0 1 1 1 2 2 2 3 3\n1:10 %% 3\n#>  [1] 1 2 0 1 2 0 1 2 0 1\n```\n:::\n\n\n模运算对于`flights`数据集来说很有用，因为我们可以使用它来将`sched_dep_time`变量分解为`hour`和`minute`。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  mutate(\n    hour = sched_dep_time %/% 100,\n    minute = sched_dep_time %% 100,\n    .keep = \"used\"\n  )\n#> # A tibble: 336,776 × 3\n#>   sched_dep_time  hour minute\n#>            <int> <dbl>  <dbl>\n#> 1            515     5     15\n#> 2            529     5     29\n#> 3            540     5     40\n#> 4            545     5     45\n#> 5            600     6      0\n#> 6            558     5     58\n#> # ℹ 336,770 more rows\n```\n:::\n\n\n我们可以将上述方法与来自 @sec-logical-summaries 的`mean(is.na(x))`技巧结合起来查看取消航班的比例在一天中的变化情况。结\n果如图 @fig-prop-cancelled 所示。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(hour = sched_dep_time %/% 100) |> \n  summarize(prop_cancelled = mean(is.na(dep_time)), n = n()) |> \n  filter(hour > 1) |> \n  ggplot(aes(x = hour, y = prop_cancelled)) +\n  geom_line(color = \"grey50\") + \n  geom_point(aes(size = n))\n```\n\n::: {.cell-output-display}\n![A line plot with scheduled departure hour on the x-axis, and proportion\nof cancelled flights on the y-axis. Cancellations seem to accumulate\nover the course of the day until 8pm, very late flights are much\nless likely to be cancelled.\n](numbers_files/figure-html/fig-prop-cancelled-1.png){#fig-prop-cancelled fig-alt='A line plot showing how proportion of cancelled flights changes over\nthe course of the day. The proportion starts low at around 0.5% at\n5am, then steadily increases over the course of the day until peaking\nat 4% at 7pm. The proportion of cancelled flights then drops rapidly\ngetting down to around 1% by midnight.' width=576}\n:::\n:::\n\n\n### 对数\n\n对数在处理跨越多个数量级的数据以及将指数增长转换为线性增长时是非常有用的转换方法。在\nR中，你可以选择三种对数：`log()`（自然对数，底为e）、`log2()`（底为2）和`log10()`（底为10）。我\n们推荐使用`log2()`或`log10()`。`l`\n`og2()`易于解释，因为在对数尺度上相差1对应于原始尺度上的加倍，相差-1对应于减半；而`log10()`易于反向转换，因为（例如）3 是 10 的 3 次方，即 1000。`l`\n`og()`的反函数是`exp()`；要计算`log2()`或`log10()`的反函数，你需要使用`2^`或`10^`。\n\n### 四舍五入 {#sec-rounding}\n\n使用`round(x)`将一个数字四舍五入到最接近的整数:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(123.456)\n#> [1] 123\n```\n:::\n\n\n你可以使用第二个参数`digits`来控制四舍五入的精度。`r`\n`ound(x, digits)`会将`x`四舍五入到最近的 `10^-n`，所以`digits = 2`会将`x`四舍五入到最近的 0.01。这\n个定义很有用，因为它意味着`round(x, -3)`会将`x`四舍五入到最近的千位，而它确实是这样做的：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(123.456, 2)  # two digits\n#> [1] 123.46\nround(123.456, 1)  # one digit\n#> [1] 123.5\nround(123.456, -1) # round to nearest ten\n#> [1] 120\nround(123.456, -2) # round to nearest hundred\n#> [1] 100\n```\n:::\n\n\n`round()`有一个看起来有些奇怪的特性，第一眼看上去这可能会让人吃惊：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(c(1.5, 2.5))\n#> [1] 2 2\n```\n:::\n\n\n`round()`使用的是所谓的“向偶数舍入”或“银行家舍入”方法：如果一个数字正好在两个整数之间，那么它会被舍入到偶数整数。这\n是一个很好的策略，因为它使得舍入是无偏的：一半的 0.5 被向上舍入，而另一半被向下舍入。\n\n`round()`与`floor()`和`ceiling()`相对应。`f`\n`loor()`总是向下舍入，而`ceiling()`总是向上舍入。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 123.456\n\nfloor(x)\n#> [1] 123\nceiling(x)\n#> [1] 124\n```\n:::\n\n\n这些函数（`floor()`和`ceiling()`）没有`digits`参数，所以你可以先将数字缩小比例，然后四舍五入，最后再扩大回原来的比例：\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Round down to nearest two digits\nfloor(x / 0.01) * 0.01\n#> [1] 123.45\n# Round up to nearest two digits\nceiling(x / 0.01) * 0.01\n#> [1] 123.46\n```\n:::\n\n\n如果你想要将`round()`舍入到某个数的倍数，你可以使用相同的技巧：\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Round to nearest multiple of 4\nround(x / 4) * 4\n#> [1] 124\n\n# Round to nearest 0.25\nround(x / 0.25) * 0.25\n#> [1] 123.5\n```\n:::\n\n\n### 将数字切分成区间\n\n使用`cut()`[^numbers-1]函数可以将一个数值向量拆分（也称为分箱或分组）成离散的区间：\n\n[^numbers-1]: `ggplot2`提供了一些辅助函数来处理`cut_interval()`,`cut_number()`和`cut_width()`中的常见情况。虽\n    然`ggplot2`是这些函数存放的一个稍显奇怪的地方，但它们作为直方图计算的一部分非常有用，并且在 tidyverse 的其他部分出现之前就已经被编写出来了。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1, 2, 5, 10, 15, 20)\ncut(x, breaks = c(0, 5, 10, 15, 20))\n#> [1] (0,5]   (0,5]   (0,5]   (5,10]  (10,15] (15,20]\n#> Levels: (0,5] (5,10] (10,15] (15,20]\n```\n:::\n\n\n`breaks`不需要是等距的：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncut(x, breaks = c(0, 5, 10, 100))\n#> [1] (0,5]    (0,5]    (0,5]    (5,10]   (10,100] (10,100]\n#> Levels: (0,5] (5,10] (10,100]\n```\n:::\n\n\n你可以选择性地提供你自己的`labels`。请\n注意，`labels`的数量应该比`breaks`少一个。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncut(x, \n  breaks = c(0, 5, 10, 15, 20), \n  labels = c(\"sm\", \"md\", \"lg\", \"xl\")\n)\n#> [1] sm sm sm md lg xl\n#> Levels: sm md lg xl\n```\n:::\n\n\n任何超出`breaks`范围的值都会变成`NA`：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny <- c(NA, -10, 5, 10, 30)\ncut(y, breaks = c(0, 5, 10, 15, 20))\n#> [1] <NA>   <NA>   (0,5]  (5,10] <NA>  \n#> Levels: (0,5] (5,10] (10,15] (15,20]\n```\n:::\n\n\n查看文档以了解其他有用的参数，如`right`和`include.lowest`，这些参数控制区间是`[a, b)`还是 `(a, b]`，以及是否应将最低区间设为`[a, b]`。\n\n### 累积和滚动聚合 {#sec-cumulative-and-rolling-aggregates}\n\n基础 R 提供了`cumsum()`,`cumprod()`,`cummin()`,`cummax()`函数，用于计算连续或累积的和、积、最小值和最大值。d\nplyr 包提供了`cummean()`函数用于计算累积平均值。在\n实践中，累积和是最常遇到的：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:10\ncumsum(x)\n#>  [1]  1  3  6 10 15 21 28 36 45 55\n```\n:::\n\n\n如果你需要更复杂的滚动或滑动聚合，可以尝试使用[slider](https://slider.r-lib.org/)包。\n\n### 练习\n\n1.  用文字解释用于生成\\@fig-prop-cancelled 的每一行代码的作用。\n\n2.  R提供了什么三角函数？猜\n    测一些名字并查找文档。这\n    些函数用度数还是弧度？\n\n3.  目前，`dep_time`和`sched_dep_time`看起来很方便，但是难以用于计算，因为它们并不是真正的连续数字。你\n    可以通过运行下面的代码来看到基本问题：每小时之间都存在间隙。\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    flights |> \n      filter(month == 1, day == 1) |> \n      ggplot(aes(x = sched_dep_time, y = dep_delay)) +\n      geom_point()\n    ```\n    :::\n\n\n    将它们转换为更真实的时间表示（可以是自午夜起的小时数（以小数形式）或分钟数）。\n\n4.  将`dep_time`和`arr_time`四舍五入到最近的五分钟。\n\n## 通用转换\n\n以下部分描述了一些通常与数值向量一起使用的通用转换，但它们也可以应用于所有其他列类型。\n\n### 秩（Ranks）\n\ndplyr 提供了一系列受 SQL 启发的排秩函数，但你应该始终从`dplyr::min_rank()`开始。它\n使用了处理并列名次（相持）的标准方法，例如，第1名、第2名、第2名、第4名。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1, 2, 2, 3, 4, NA)\nmin_rank(x)\n#> [1]  1  2  2  4  5 NA\n```\n:::\n\n\n请注意，最小的值获得最小的秩；利用`desc(x)`可以让最大的值获得最小的秩：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmin_rank(desc(x))\n#> [1]  5  3  3  2  1 NA\n```\n:::\n\n\n如果`min_rank()`不符合你的需求，请查看它的变体函数`dplyr::row_number()`、`dplyr::dense_rank()`、`dplyr::percent_rank()`和`dplyr::cume_dist()`。查\n看文档以获取详细信息。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- tibble(x = x)\ndf |> \n  mutate(\n    row_number = row_number(x),\n    dense_rank = dense_rank(x),\n    percent_rank = percent_rank(x),\n    cume_dist = cume_dist(x)\n  )\n#> # A tibble: 6 × 5\n#>       x row_number dense_rank percent_rank cume_dist\n#>   <dbl>      <int>      <int>        <dbl>     <dbl>\n#> 1     1          1          1         0          0.2\n#> 2     2          2          2         0.25       0.6\n#> 3     2          3          2         0.25       0.6\n#> 4     3          4          3         0.75       0.8\n#> 5     4          5          4         1          1  \n#> 6    NA         NA         NA        NA         NA\n```\n:::\n\n\n你可以通过选择适当的`ties.method`参数来使用 R 的基础函数`rank()`来达到许多相同的结果；你也可能希望通过设置`na.last = \"keep\"`将 `NA`s 值保留为 `NA`。\n\n`row_number()`在 dplyr 的函数内部使用时也可以不带任何参数。在\n这种情况下它会给出“当前”行的编号。当\n与`%%`或`%/%`结合使用时，它可以成为将数据划分为大小相似的组的有用工具：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- tibble(id = 1:10)\n\ndf |> \n  mutate(\n    row0 = row_number() - 1,\n    three_groups = row0 %% 3,\n    three_in_each_group = row0 %/% 3\n  )\n#> # A tibble: 10 × 4\n#>      id  row0 three_groups three_in_each_group\n#>   <int> <dbl>        <dbl>               <dbl>\n#> 1     1     0            0                   0\n#> 2     2     1            1                   0\n#> 3     3     2            2                   0\n#> 4     4     3            0                   1\n#> 5     5     4            1                   1\n#> 6     6     5            2                   1\n#> # ℹ 4 more rows\n```\n:::\n\n\n### 偏移量（Offsets）\n\n`dplyr::lead()`和`dplyr::lag()`允许你引用“当前”值之前或之后的值。它\n们会返回一个与输入长度相同的向量，并在开始或结束时用 `NA`s 填充：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(2, 5, 11, 11, 19, 35)\nlag(x)\n#> [1] NA  2  5 11 11 19\nlead(x)\n#> [1]  5 11 11 19 35 NA\n```\n:::\n\n\n-   `x - lag(x)` 给出当前值和前一个值之间的差值。\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    x - lag(x)\n    #> [1] NA  3  6  0  8 16\n    ```\n    :::\n\n\n-   `x == lag(x)` 告诉你当前值何时发生改变。\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    x == lag(x)\n    #> [1]    NA FALSE FALSE  TRUE FALSE FALSE\n    ```\n    :::\n\n\n你可以通过使用第二个参数`n`来实现超过一个位置的向前或向后取值。\n\n### 连续标识符\n\n有时，每当某个事件发生时你都希望开始一个新组。例\n如在查看网站数据时，你通常会希望将事件划分为不同会话（sessions），即当距离上次活动超过 `x` 分钟时你会开始一个新会话。比\n如，想象你有某人访问网站的时间记录：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevents <- tibble(\n  time = c(0, 1, 2, 3, 5, 10, 12, 15, 17, 19, 20, 27, 28, 30)\n)\n```\n:::\n\n\n并且你已经计算了每个事件之间的时间间隔，并判断了是否存在足够大的间隔以符合标准：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevents <- events |> \n  mutate(\n    diff = time - lag(time, default = first(time)),\n    has_gap = diff >= 5\n  )\nevents\n#> # A tibble: 14 × 3\n#>    time  diff has_gap\n#>   <dbl> <dbl> <lgl>  \n#> 1     0     0 FALSE  \n#> 2     1     1 FALSE  \n#> 3     2     1 FALSE  \n#> 4     3     1 FALSE  \n#> 5     5     2 FALSE  \n#> 6    10     5 TRUE   \n#> # ℹ 8 more rows\n```\n:::\n\n\n但是，我们如何从逻辑向量转换为可以使用`group_by()`进行分组的东西呢？`c`\n`umsum()`函数（来自 @sec-cumulative-and-rolling-aggregates ）此时就派上了用场，当存在间隔（即`has_gap`为`TRUE`）时，它会增加分组编号（来自\\@sec-numeric-summaries-of-logicals ）：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevents |> mutate(\n  group = cumsum(has_gap)\n)\n#> # A tibble: 14 × 4\n#>    time  diff has_gap group\n#>   <dbl> <dbl> <lgl>   <int>\n#> 1     0     0 FALSE       0\n#> 2     1     1 FALSE       0\n#> 3     2     1 FALSE       0\n#> 4     3     1 FALSE       0\n#> 5     5     2 FALSE       0\n#> 6    10     5 TRUE        1\n#> # ℹ 8 more rows\n```\n:::\n\n\n创建分组变量的另一种方法是`consecutive_id()`，它会在其参数之一发生变化时开始一个新组。例\n如，受到[this stackoverflow question](https://stackoverflow.com/questions/27482712)的启发，假设你有一个包含许多重复值的数据框：\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- tibble(\n  x = c(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"d\", \"e\", \"a\", \"a\", \"b\", \"b\"),\n  y = c(1, 2, 3, 2, 4, 1, 3, 9, 4, 8, 10, 199)\n)\n```\n:::\n\n\n如果你想要保留每个重复值`x`的第一行，你可以使用`group_by()`、`consecutive_id()`和`slice_head()`。\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  group_by(id = consecutive_id(x)) |> \n  slice_head(n = 1)\n#> # A tibble: 7 × 3\n#> # Groups:   id [7]\n#>   x         y    id\n#>   <chr> <dbl> <int>\n#> 1 a         1     1\n#> 2 b         2     2\n#> 3 c         4     3\n#> 4 d         3     4\n#> 5 e         9     5\n#> 6 a         4     6\n#> # ℹ 1 more row\n```\n:::\n\n\n### 练习\n\n1.  使用排秩函数找出延误时间最长的10个航班。如\n    果出现并列的情况，你打算如何处理？请\n    仔细阅读`min_rank()`函数的文档。\n\n2.  哪架飞机（`tailnum`）的准时记录最差？\n\n3.  如果你想尽可能避免延误，你应该在一天中的哪个时间段飞行？\n\n4.  `flights |> group_by(dest) |> filter(row_number() < 4)`这段代码做了什么？`f`\n    `lights |> group_by(dest) |> filter(row_number(dep_delay) < 4)`这段代码又做了什么？\n\n5.  对于每个目的地，计算延误的总分钟数；对于每个航班，计算其目的地延误总时间中所占的比例。\n\n6.  延误通常是时间相关的：即使导致初始延误的问题已经解决，后续的航班仍然会延误以允许前面的航班起飞。使\n    用`lag()`函数，探索某小时的平均航班延误与前一小时的平均延误之间的关系。\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    flights |> \n      mutate(hour = dep_time %/% 100) |> \n      group_by(year, month, day, hour) |> \n      summarize(\n        dep_delay = mean(dep_delay, na.rm = TRUE),\n        n = n(),\n        .groups = \"drop\"\n      ) |> \n      filter(n > 5)\n    ```\n    :::\n\n\n7.  查看每个目的地，你能找到那些可疑的快速航班（即可能存在数据录入错误的航班）吗？计\n    算某航班的空中飞行时间与该目的地最短飞行时间的相对值。哪\n    些航班在空中延误最严重？\n\n8.  找出至少由两家航空公司运营的所有目的地。使\n    用这些目的地，根据同一目的地的表现，对航空公司进行相对排名。\n\n## 数值汇总\n\n仅使用我们已经介绍过的`counts`、`means`和`sums`就可以让你走得很远，但R提供了许多其他有用的汇总函数。以\n下是可能会有用的一些函数。\n\n### 中心\n\n到目前为止，我们主要使用`mean()`来汇总数值向量的中心。正\n如在\\@sec-sample-size 看到的，由于均数是总和除以总数得到的，因此即使对几个异常高或异常低的值它也很敏感。一\n种替代方法是使用`median()`，它会找到一个位于向量“中间”的值，即50%的值高于它，50%的值低于它。根\n据你感兴趣的变量的分布形状，选取均数或者中位数作为合适的中心度量标准。例\n如对于对称分布我们通常报告均数，而对于偏态分布则报告中位数。\n\n@fig-mean-vs-median 比较了每个目的地的起飞延误均数与中位数（以分钟为单位）。延\n误中位数总是小于延误均数，因为航班有时会延误数小时，但永远不会提前数小时起飞。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |>\n  group_by(year, month, day) |>\n  summarize(\n    mean = mean(dep_delay, na.rm = TRUE),\n    median = median(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |> \n  ggplot(aes(x = mean, y = median)) + \n  geom_abline(slope = 1, intercept = 0, color = \"white\", linewidth = 2) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![A scatterplot showing the differences of summarizing daily departure\ndelay with median instead of mean.\n](numbers_files/figure-html/fig-mean-vs-median-1.png){#fig-mean-vs-median fig-alt='All points fall below a 45° line, meaning that the median delay is\nalways less than the mean delay. Most points are clustered in a\ndense region of mean [0, 20] and median [-5, 5]. As the mean delay\nincreases, the spread of the median also increases. There are two\noutlying points with mean ~60, median ~30, and mean ~85, median ~55.' width=576}\n:::\n:::\n\n\n你可能还想知道众数（mode），也就是最常见的值。这\n是一种仅在非常简单的情况下才有效的汇总统计量（这就是为什么你可能在高中学过它），但它在许多真实数据集上并不适用。如\n果数据是离散的，可能存在多个最常见的值，而如果数据是连续的，则可能没有最常见的值，因为每个值都略有不同。由\n于这些原因，统计学家往往不使用众数，并且在R的基础包中也没有包含计算众数[^numbers-2]的函数。\n\n[^numbers-2]: `mode()` 函数做的是完全不同的事情!\n\n### 最小值、最大值和分位数 {#sec-min-max-summary}\n\n如果你对中心位置以外的其他位置感兴趣怎么办？`m`\n`in()`和`max()`会给你最大值和最小值。另\n一个强大的工具是`quantile()`，它是中位数的泛化：`quantile(x, 0.25)`会找到大于 25% 的`x`的值，`quantile(x, 0.5)`相当于中位数，而`quantile(x, 0.95)`会找到大于 95% 的`x`的值。\n\n对于`flights`数据，你可能想查看延误的 95% 分位数而不是最大值，因为它会忽略延误最严重的 5% 航班，这部分航班可能非常极端。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |>\n  group_by(year, month, day) |>\n  summarize(\n    max = max(dep_delay, na.rm = TRUE),\n    q95 = quantile(dep_delay, 0.95, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#> # A tibble: 365 × 5\n#>    year month   day   max   q95\n#>   <int> <int> <int> <dbl> <dbl>\n#> 1  2013     1     1   853  70.1\n#> 2  2013     1     2   379  85  \n#> 3  2013     1     3   291  68  \n#> 4  2013     1     4   288  60  \n#> 5  2013     1     5   327  41  \n#> 6  2013     1     6   202  51  \n#> # ℹ 359 more rows\n```\n:::\n\n\n### 离散性（Spread）\n\n有时你并不是那么关心大部分数据所在的位置，而是关心它的离散程度。两\n个常用的汇总统计量是标准差`sd(x)`和四分位距`IQR()`。我\n们在这里不会解释`sd()`，因为你可能已经很熟悉了，但`IQR()`可能比较新颖，它等于`quantile(x, 0.75) - quantile(x, 0.25)`，给出了包含中间 50% 数据的范围。\n\n我们可以利用这个方法来揭示`flights`数据中的一个小异常。你\n可能会认为，由于机场总是在固定的位置，所以起点和终点之间距离的离散性应该是零。但\n是下面的代码揭示了机场 [EGE](https://en.wikipedia.org/wiki/Eagle_County_Regional_Airport) 的一个数据异常：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(origin, dest) |> \n  summarize(\n    distance_iqr = IQR(distance), \n    n = n(),\n    .groups = \"drop\"\n  ) |> \n  filter(distance_iqr > 0)\n#> # A tibble: 2 × 4\n#>   origin dest  distance_iqr     n\n#>   <chr>  <chr>        <dbl> <int>\n#> 1 EWR    EGE              1   110\n#> 2 JFK    EGE              1   103\n```\n:::\n\n\n### 分布\n\n值得记住的是，上述所有描述的汇总统计量都是将分布简化为单个数字的一种方式。这\n意味着它们本质上是简化的，如果你选择了错误的汇总方式，很容易忽略各组之间的重要差异。因\n此，在确定汇总统计量之前，先对数据进行可视化始终是个好主意。\n\n@fig-flights-dist 显示了出发延误的整体分布。这\n个分布是如此偏斜，以至于我们必须放大才能看到大部分数据。这\n表明均数可能不是一个好的汇总方式，我们可能更喜欢使用中位数。\n\n\n::: {.cell}\n::: {.cell-output-display}\n![(Left) The histogram of the full data is extremely skewed making it\nhard to get any details. (Right) Zooming into delays of less than two\nhours makes it possible to see what's happening with the bulk of the\nobservations.\n](numbers_files/figure-html/fig-flights-dist-1.png){#fig-flights-dist fig-alt='Two histograms of `dep_delay`. On the left, it\\'s very hard to see\nany pattern except that there\\'s a very large spike around zero, the\nbars rapidly decay in height, and for most of the plot, you can\\'t\nsee any bars because they are too short to see. On the right,\nwhere we\\'ve discarded delays of greater than two hours, we can\nsee that the spike occurs slightly below zero (i.e. most flights\nleave a couple of minutes early), but there\\'s still a very steep\ndecay after that.\n' width=576}\n:::\n:::\n\n\n同样，检查子组的分布是否与整体相似也是一个好主意。在\n下面的图中，`dep_delay`的365个频数多边形图（frequency polygons）被叠加在一起，每天一个。这\n些分布似乎遵循一个共同的模式，这表明每天使用相同的汇总方式是合适的。\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |>\n  filter(dep_delay < 120) |> \n  ggplot(aes(x = dep_delay, group = interaction(day, month))) + \n  geom_freqpoly(binwidth = 5, alpha = 1/5)\n```\n\n::: {.cell-output-display}\n![](numbers_files/figure-html/unnamed-chunk-50-1.png){fig-alt='The distribution of `dep_delay` is highly right skewed with a strong\npeak slightly less than 0. The 365 frequency polygons are mostly\noverlapping forming a thick black band.' width=576}\n:::\n:::\n\n\n不要害怕探讨针对你正在处理的数据自定义的汇总方法。在\n这种情况下，这可能意味着分别汇总提前起飞的航班和晚起飞的航班的分布，或者鉴于这些值严重偏斜，你可能还需尝试进行对数转换。最\n后，不要忘记在\\@sec-sample-size 中学到的内容：每当创建数值汇总时，最好包括每个组的观测数。\n\n### 位置\n\n对于数值向量，还有最后一种类型的汇总统计量非常有用，它也适用于其他类型的值：提取特定位置的值：`first(x)`、`last(x)` 和 `nth(x, n)`。\n\n例如，我们可以找到每天第一次、第五次和最后一次的出发时间：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(year, month, day) |> \n  summarize(\n    first_dep = first(dep_time, na_rm = TRUE), \n    fifth_dep = nth(dep_time, 5, na_rm = TRUE),\n    last_dep = last(dep_time, na_rm = TRUE)\n  )\n#> `summarise()` has grouped output by 'year', 'month'. You can override using\n#> the `.groups` argument.\n#> # A tibble: 365 × 6\n#> # Groups:   year, month [12]\n#>    year month   day first_dep fifth_dep last_dep\n#>   <int> <int> <int>     <int>     <int>    <int>\n#> 1  2013     1     1       517       554     2356\n#> 2  2013     1     2        42       535     2354\n#> 3  2013     1     3        32       520     2349\n#> 4  2013     1     4        25       531     2358\n#> 5  2013     1     5        14       534     2357\n#> 6  2013     1     6        16       555     2355\n#> # ℹ 359 more rows\n```\n:::\n\n\n(注意：因为dplyr函数使用`_`来分隔函数名和参数名的组件，所以这些函数使用`na_rm`而不是`na.rm`）\n\n如果你熟悉`[`操作符，我们将在\\@sec-subset-many 中再次讨论它，你可能会想是否需要这些函数。有\n三个原因：默认参数允许你在指定的位置不存在时提供一个默认值，`order_by`参数允许你局部覆盖行的顺序，而`na_rm`参数允许你删除缺失值。\n\n按位置提取值是对按秩筛选的补充。筛\n选操作会返回所有变量，每个观测都在单独的一行中：\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights |> \n  group_by(year, month, day) |> \n  mutate(r = min_rank(sched_dep_time)) |> \n  filter(r %in% c(1, max(r)))\n#> # A tibble: 1,195 × 20\n#> # Groups:   year, month, day [365]\n#>    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#>   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n#> 1  2013     1     1      517            515         2      830            819\n#> 2  2013     1     1     2353           2359        -6      425            445\n#> 3  2013     1     1     2353           2359        -6      418            442\n#> 4  2013     1     1     2356           2359        -3      425            437\n#> 5  2013     1     2       42           2359        43      518            442\n#> 6  2013     1     2      458            500        -2      703            650\n#> # ℹ 1,189 more rows\n#> # ℹ 12 more variables: arr_delay <dbl>, carrier <chr>, flight <int>, …\n```\n:::\n\n\n### 利用 `mutate()`\n\n顾名思义，汇总函数通常与`summarize()`一起使用。但\n是，因为我们在\\@sec-recycling 中讨论的循环规则，它们也可以与`mutate()`一起使用，特别是当你想进行某种分组标准化时。例\n如：\n\n-   `x / sum(x)` 计算了`x`中每个元素占总和的比例；\n-   `(x - mean(x)) / sd(x)` 计算Z-score（将`x`标准化为均数为0，标准差为1）；\n-   `(x - min(x)) / (max(x) - min(x))` 将`x`标准化到范围\\[0, 1\\]；\n-   `x / first(x)` 基于第一个观测值计算一个指数。\n\n### 练习\n\n1.  头脑风暴至少5种不同的方法来评估一组航班的典型延误特性。什\n    么时候用`mean()`？什\n    么时候用`median()`？什\n    么情况下你可能想使用其他方法？你\n    应该使用到达延误还是起飞延误？为\n    什么你可能想使用来自`planes`的数据？\n\n2.  哪些目的地的航速变化最大？\n\n3.  创建一个图来进一步探索EGE的冒险经历。\n    你能找到机场变换位置的任何证据吗？你\n    能找到可解释这种差异的另一个变量吗？\n\n## 小结\n\n你已经熟悉了许多用于数字处理的工具，在阅读本章之后也知道了如何在R中使用它们。你\n还学习了一些有用的通用转换方法，这些方法通常（但不仅限于）应用于数字向量，如秩和偏移量。最\n后，通过一些数字汇总进行了实践，并讨论了几个你应该考虑的统计学挑战。\n\n在接下来的两章中，我们将使用`stringr`包深入研究字符串的处理。字\n符串是一个很大的主题，因此它们被分为两章，一章关于字符串的基础知识，另一章关于正则表达式。\n",
    "supporting": [
      "numbers_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}